{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "from tensorflow.keras.models import Sequential, save_model, load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential #Initialise our neural network model as a sequential network\n",
    "from keras.layers import Conv2D #Convolution operation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Activation#Applies activation function\n",
    "from keras.layers import Dropout#Prevents overfitting by randomly converting few outputs to zero\n",
    "from keras.layers import MaxPooling2D # Maxpooling function\n",
    "from keras.layers import Flatten # Converting 2D arrays into a 1D linear vector\n",
    "from keras.layers import Dense # Regular fully connected neural network\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'test_image1.png'\n",
    "image_id = 1\n",
    "cascPath = \"haarcascade_frontalface_default.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath = 'test_image1.png'\n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "img = cv2.imread(imagePath)\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "faces = faceCascade.detectMultiScale(\n",
    "gray,\n",
    "scaleFactor=1.1,\n",
    "minNeighbors=5,\n",
    "minSize=(30, 30),\n",
    "flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "print(\"Found {0} faces!\".format(len(faces)))\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "cv2.imshow(\"Faces found\", img)\n",
    "cv2.waitKey(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('fer.json','r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.load_weights(\"fer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_model = load_model('pre-trained/gender_detection.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 48\n",
    "HEIGHT = 48\n",
    "x=None\n",
    "y=None\n",
    "labels_emo = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "labels_gen = ['Man','Woman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb = cv2.imread(image)\n",
    "img_gray=cv2.cvtColor(img_rgb,cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "faces = faceCascade.detectMultiScale(\n",
    "        img_gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "        flags = cv2.CASCADE_SCALE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion: Happy\n",
      "Emotion: Happy\n",
      "Emotion: Surprise\n",
      "Emotion: Fear\n"
     ]
    }
   ],
   "source": [
    "emotion=[]\n",
    "for (x, y, w, h) in faces:\n",
    "        roi_gray = img_gray[y:y + h, x:x + w]\n",
    "        cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (48, 48)), -1), 0)\n",
    "        cv2.normalize(cropped_img, cropped_img, alpha=0, beta=1, norm_type=cv2.NORM_L2, dtype=cv2.CV_32F)\n",
    "        cv2.rectangle(img_rgb, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "        #predicting the emotion\n",
    "        yhat= loaded_model.predict(cropped_img)\n",
    "        cv2.putText(img_rgb, labels_emo[int(np.argmax(yhat))], (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "        print(\"Emotion: \"+labels_emo[int(np.argmax(yhat))])\n",
    "        emotion.append(labels_emo[int(np.argmax(yhat))])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender: Man\n",
      "Gender: Man\n",
      "Gender: Woman\n",
      "Gender: Man\n"
     ]
    }
   ],
   "source": [
    "gender=[]\n",
    "for (x, y, w, h) in faces:\n",
    "        roi_rgb = img_rgb[y:y + h, x:x + w]\n",
    "        cropped_img = cv2.resize(roi_rgb, (96,96))\n",
    "        cropped_img = cropped_img.astype(\"float\") / 255.0\n",
    "        cropped_img = img_to_array(cropped_img)\n",
    "        cropped_img = np.expand_dims(cropped_img, axis=0)\n",
    "        #predicting the gender\n",
    "        ghat= gender_model.predict(cropped_img)\n",
    "        cv2.putText(img_rgb, labels_gen[int(np.argmax(ghat))], (x, y+100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        print(\"Gender: \"+labels_gen[int(np.argmax(ghat))])\n",
    "        gender.append(labels_gen[int(np.argmax(ghat))])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Emotion', img_rgb)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=[]\n",
    "i=1\n",
    "while(l!=0):\n",
    "    k.append(i)\n",
    "    i=i+1\n",
    "    l= l-1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=[]\n",
    "for x in gender:\n",
    "    if x=='Man':\n",
    "        g.append(1)\n",
    "    else:\n",
    "        g.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 1]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "e=[]\n",
    "for x in emotion:\n",
    "    if x=='Anger':\n",
    "        e.append(1)\n",
    "    elif x=='Disgust':\n",
    "        e.append(2)\n",
    "    elif x=='Fear':\n",
    "        e.append(3)\n",
    "    elif x=='Happy':\n",
    "        e.append(4)\n",
    "    elif x=='Sad':\n",
    "        e.append(5)\n",
    "    elif x=='Surprise':\n",
    "        e.append(6)\n",
    "    elif x=='Neutral':\n",
    "        e.append(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, 6, 3]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.DataFrame({'Face_id':k,'Image_id':image_id,'gender':g,'emotion':e})\n",
    "df2 = pd.DataFrame({'Gender_id':[1,2],'Gender':['Man','Woman']})\n",
    "df3 = pd.DataFrame({'Emotion_id':[1,2,3,4,5,6,7],'Emotion':['Anger','Disgust','Fear','Happy','Sad','Surprise','Neutral']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('multiple.xlsx', engine='xlsxwriter')\n",
    "df1.to_excel(writer, sheet_name='Sheeta')\n",
    "df2.to_excel(writer, sheet_name='Sheetb')\n",
    "df3.to_excel(writer, sheet_name='Sheetc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({'Data': ['a', 'b', 'c', 'd']})\n",
    "\n",
    "df2 = pd.DataFrame({'Data': [1, 2, 3, 4]})\n",
    "\n",
    "df3 = pd.DataFrame({'Data': [1.1, 1.2, 1.3, 1.4]})\n",
    "\n",
    "writer = pd.ExcelWriter('multiple.xlsx', engine='xlsxwriter')\n",
    "\n",
    "df1.to_excel(writer, sheet_name='Sheeta')\n",
    "\n",
    "df2.to_excel(writer, sheet_name='Sheetb')\n",
    "\n",
    "df3.to_excel(writer, sheet_name='Sheetc')\n",
    "\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
