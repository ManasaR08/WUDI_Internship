{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotion_detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAmxf5dnjRvC",
        "outputId": "e9ac71b2-b0b3-47b7-d814-6b14af720b0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCtslIeGk_KE",
        "outputId": "3a9eb1ed-d1f2-4323-a020-c72389cd114d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/gdrive/My\\ Drive/WUDI\\ Internship\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/WUDI Internship\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYUOxAJ3Co5g",
        "outputId": "cd094b7f-fdeb-4272-e155-d3692df07202",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd Assignment1-GenderEmotion detection"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/WUDI Internship/Assignment1-GenderEmotion detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dJ862hva1F2",
        "outputId": "b59dd3a6-e6b5-46a8-ae43-a42fa5e82cf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd emotion_detection/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/WUDI Internship/Assignment1-GenderEmotion detection/emotion_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V27WUpNa-ud"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.models import Sequential #Initialise our neural network model as a sequential network\n",
        "from keras.layers import Conv2D #Convolution operation\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import Activation#Applies activation function\n",
        "from keras.layers import Dropout#Prevents overfitting by randomly converting few outputs to zero\n",
        "from keras.layers import MaxPooling2D # Maxpooling function\n",
        "from keras.layers import Flatten # Converting 2D arrays into a 1D linear vector\n",
        "from keras.layers import Dense # Regular fully connected neural network\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard, ModelCheckpoint\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R2b5QLBnE1O"
      },
      "source": [
        "#Code source: https://www.freecodecamp.org/news/facial-emotion-recognition-develop-a-c-n-n-and-break-into-kaggle-top-10-f618c024faa7/\n",
        "\n",
        "def load_data(dataset_path):\n",
        "  \n",
        "  #classes = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprsie', 'Neutral']  #We will be dealing with seven different types of emotions.\n",
        "\n",
        "  data = []\n",
        "  test_data = []\n",
        "  test_labels = []\n",
        "  labels =[]\n",
        "\n",
        "  with open(dataset_path, 'r') as file:\n",
        "      for line_no, line in enumerate(file.readlines()):\n",
        "          if 0 < line_no <= 35887:\n",
        "            curr_class, line, set_type = line.split(',')\n",
        "            image_data = np.asarray([int(x) for x in line.split()]).reshape(48, 48)#Creating a list out of the string then converting it into a 2-Dimensional numpy array.\n",
        "            image_data =image_data.astype(np.uint8)/255.0\n",
        "            \n",
        "            if (set_type.strip() == 'PrivateTest'):\n",
        "              \n",
        "              test_data.append(image_data)\n",
        "              test_labels.append(curr_class)\n",
        "            else:\n",
        "              data.append(image_data)\n",
        "              labels.append(curr_class)\n",
        "      \n",
        "      test_data = np.expand_dims(test_data, -1)\n",
        "      test_labels = to_categorical(test_labels, num_classes = 7)\n",
        "      data = np.expand_dims(data, -1)   \n",
        "      labels = to_categorical(labels, num_classes = 7)\n",
        "    \n",
        "      return np.array(data), np.array(labels), np.array(test_data), np.array(test_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRb1IlOdnKPN",
        "outputId": "9a17025c-b0cb-4152-80be-3110239bd4eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset_path = \"fer2013/fer2013.csv\" \n",
        "train_data, train_labels, test_data, test_labels = load_data(dataset_path)\n",
        "#train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size = test_size,random_state = seed)\n",
        "\n",
        "print(\"Number of images in Training set:\", len(train_data))\n",
        "print(\"Number of images in Test set:\", len(test_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of images in Training set: 32298\n",
            "Number of images in Test set: 3589\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xcdi70KenQPT",
        "outputId": "8af33b5f-3af1-4cd9-e196-ddb2fdb2ae7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epochs = 100\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "\n",
        "model = Sequential()\n",
        "    \n",
        "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(48, 48, 1), kernel_regularizer=l2(0.01)))\n",
        "model.add(Conv2D(64, (3, 3), padding='same',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "    \n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "    \n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "    \n",
        "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(7, activation='softmax'))\n",
        "adam = optimizers.Adam(lr = learning_rate)\n",
        "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "print(model.summary())\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3)\n",
        "early_stopper = EarlyStopping(monitor='val_acc', min_delta=0, patience=6, mode='auto')\n",
        "checkpointer = ModelCheckpoint('weights.hd5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "model.fit(\n",
        "          train_data,\n",
        "          train_labels,\n",
        "          epochs = epochs,\n",
        "          batch_size = batch_size,\n",
        "          validation_split = 0.2,\n",
        "          shuffle = True,\n",
        "          callbacks=[lr_reducer, checkpointer, early_stopper]\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_11 (Conv2D)           (None, 46, 46, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 46, 46, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 46, 46, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 23, 23, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 23, 23, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 23, 23, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 23, 23, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 23, 23, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 23, 23, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 11, 11, 256)       295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 11, 11, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 11, 11, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 11, 11, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 11, 11, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 11, 11, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 5, 5, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 5, 5, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 5, 5, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 5, 5, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 5, 5, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 5, 5, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 7)                 455       \n",
            "=================================================================\n",
            "Total params: 9,014,727\n",
            "Trainable params: 9,009,223\n",
            "Non-trainable params: 5,504\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "404/404 [==============================] - ETA: 0s - loss: 2.1277 - accuracy: 0.1966\n",
            "Epoch 00001: val_loss improved from inf to 1.87536, saving model to weights.hd5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: weights.hd5/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 33s 81ms/step - loss: 2.1277 - accuracy: 0.1966 - val_loss: 1.8754 - val_accuracy: 0.2489\n",
            "Epoch 2/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.8668 - accuracy: 0.2321\n",
            "Epoch 00002: val_loss improved from 1.87536 to 1.83445, saving model to weights.hd5\n",
            "INFO:tensorflow:Assets written to: weights.hd5/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 31s 76ms/step - loss: 1.8668 - accuracy: 0.2321 - val_loss: 1.8345 - val_accuracy: 0.2489\n",
            "Epoch 3/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.8436 - accuracy: 0.2444\n",
            "Epoch 00003: val_loss improved from 1.83445 to 1.83144, saving model to weights.hd5\n",
            "INFO:tensorflow:Assets written to: weights.hd5/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 31s 77ms/step - loss: 1.8436 - accuracy: 0.2444 - val_loss: 1.8314 - val_accuracy: 0.2489\n",
            "Epoch 4/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.8327 - accuracy: 0.2493\n",
            "Epoch 00004: val_loss improved from 1.83144 to 1.82407, saving model to weights.hd5\n",
            "INFO:tensorflow:Assets written to: weights.hd5/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 31s 77ms/step - loss: 1.8327 - accuracy: 0.2494 - val_loss: 1.8241 - val_accuracy: 0.2489\n",
            "Epoch 5/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.8271 - accuracy: 0.2499\n",
            "Epoch 00005: val_loss improved from 1.82407 to 1.81758, saving model to weights.hd5\n",
            "INFO:tensorflow:Assets written to: weights.hd5/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 31s 78ms/step - loss: 1.8272 - accuracy: 0.2499 - val_loss: 1.8176 - val_accuracy: 0.2489\n",
            "Epoch 6/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.8194 - accuracy: 0.2507\n",
            "Epoch 00006: val_loss improved from 1.81758 to 1.81073, saving model to weights.hd5\n",
            "INFO:tensorflow:Assets written to: weights.hd5/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 31s 77ms/step - loss: 1.8196 - accuracy: 0.2505 - val_loss: 1.8107 - val_accuracy: 0.2489\n",
            "Epoch 7/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.8138 - accuracy: 0.2511\n",
            "Epoch 00007: val_loss improved from 1.81073 to 1.80962, saving model to weights.hd5\n",
            "INFO:tensorflow:Assets written to: weights.hd5/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 31s 76ms/step - loss: 1.8139 - accuracy: 0.2511 - val_loss: 1.8096 - val_accuracy: 0.2489\n",
            "Epoch 8/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.8061 - accuracy: 0.2517\n",
            "Epoch 00008: val_loss improved from 1.80962 to 1.80858, saving model to weights.hd5\n",
            "INFO:tensorflow:Assets written to: weights.hd5/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 31s 78ms/step - loss: 1.8059 - accuracy: 0.2520 - val_loss: 1.8086 - val_accuracy: 0.2489\n",
            "Epoch 9/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.7961 - accuracy: 0.2549\n",
            "Epoch 00009: val_loss did not improve from 1.80858\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 26s 64ms/step - loss: 1.7962 - accuracy: 0.2549 - val_loss: 1.8268 - val_accuracy: 0.2489\n",
            "Epoch 10/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.7637 - accuracy: 0.2755\n",
            "Epoch 00010: val_loss did not improve from 1.80858\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 26s 64ms/step - loss: 1.7635 - accuracy: 0.2756 - val_loss: 1.8934 - val_accuracy: 0.2489\n",
            "Epoch 11/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.7292 - accuracy: 0.2943\n",
            "Epoch 00011: val_loss improved from 1.80858 to 1.68082, saving model to weights.hd5\n",
            "INFO:tensorflow:Assets written to: weights.hd5/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 31s 76ms/step - loss: 1.7292 - accuracy: 0.2940 - val_loss: 1.6808 - val_accuracy: 0.3127\n",
            "Epoch 12/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.6863 - accuracy: 0.3095\n",
            "Epoch 00012: val_loss did not improve from 1.68082\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 26s 64ms/step - loss: 1.6865 - accuracy: 0.3095 - val_loss: 1.7046 - val_accuracy: 0.3107\n",
            "Epoch 13/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.6516 - accuracy: 0.3170\n",
            "Epoch 00013: val_loss improved from 1.68082 to 1.66595, saving model to weights.hd5\n",
            "INFO:tensorflow:Assets written to: weights.hd5/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 31s 76ms/step - loss: 1.6516 - accuracy: 0.3170 - val_loss: 1.6659 - val_accuracy: 0.3317\n",
            "Epoch 14/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.5904 - accuracy: 0.3599\n",
            "Epoch 00014: val_loss improved from 1.66595 to 1.58588, saving model to weights.hd5\n",
            "INFO:tensorflow:Assets written to: weights.hd5/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 31s 77ms/step - loss: 1.5907 - accuracy: 0.3599 - val_loss: 1.5859 - val_accuracy: 0.3649\n",
            "Epoch 15/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.5377 - accuracy: 0.3855\n",
            "Epoch 00015: val_loss did not improve from 1.58588\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 26s 63ms/step - loss: 1.5380 - accuracy: 0.3856 - val_loss: 1.6205 - val_accuracy: 0.3560\n",
            "Epoch 16/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.4860 - accuracy: 0.4088\n",
            "Epoch 00016: val_loss improved from 1.58588 to 1.42776, saving model to weights.hd5\n",
            "INFO:tensorflow:Assets written to: weights.hd5/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 31s 76ms/step - loss: 1.4858 - accuracy: 0.4089 - val_loss: 1.4278 - val_accuracy: 0.4211\n",
            "Epoch 17/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.4639 - accuracy: 0.4178\n",
            "Epoch 00017: val_loss improved from 1.42776 to 1.42063, saving model to weights.hd5\n",
            "INFO:tensorflow:Assets written to: weights.hd5/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 31s 76ms/step - loss: 1.4638 - accuracy: 0.4178 - val_loss: 1.4206 - val_accuracy: 0.4279\n",
            "Epoch 18/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.4270 - accuracy: 0.4275\n",
            "Epoch 00018: val_loss did not improve from 1.42063\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 26s 64ms/step - loss: 1.4270 - accuracy: 0.4274 - val_loss: 1.5465 - val_accuracy: 0.4045\n",
            "Epoch 19/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.4114 - accuracy: 0.4288\n",
            "Epoch 00019: val_loss improved from 1.42063 to 1.39831, saving model to weights.hd5\n",
            "INFO:tensorflow:Assets written to: weights.hd5/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 30s 75ms/step - loss: 1.4119 - accuracy: 0.4288 - val_loss: 1.3983 - val_accuracy: 0.4438\n",
            "Epoch 20/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.3867 - accuracy: 0.4433\n",
            "Epoch 00020: val_loss improved from 1.39831 to 1.39356, saving model to weights.hd5\n",
            "INFO:tensorflow:Assets written to: weights.hd5/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 31s 76ms/step - loss: 1.3871 - accuracy: 0.4431 - val_loss: 1.3936 - val_accuracy: 0.4523\n",
            "Epoch 21/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.3777 - accuracy: 0.4453\n",
            "Epoch 00021: val_loss did not improve from 1.39356\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 1.3775 - accuracy: 0.4453 - val_loss: 1.4066 - val_accuracy: 0.4531\n",
            "Epoch 22/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.3686 - accuracy: 0.4461\n",
            "Epoch 00022: val_loss improved from 1.39356 to 1.38069, saving model to weights.hd5\n",
            "INFO:tensorflow:Assets written to: weights.hd5/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 31s 76ms/step - loss: 1.3687 - accuracy: 0.4462 - val_loss: 1.3807 - val_accuracy: 0.4550\n",
            "Epoch 23/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.3469 - accuracy: 0.4516\n",
            "Epoch 00023: val_loss improved from 1.38069 to 1.33730, saving model to weights.hd5\n",
            "INFO:tensorflow:Assets written to: weights.hd5/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 30s 75ms/step - loss: 1.3470 - accuracy: 0.4514 - val_loss: 1.3373 - val_accuracy: 0.4542\n",
            "Epoch 24/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.3288 - accuracy: 0.4583\n",
            "Epoch 00024: val_loss improved from 1.33730 to 1.32458, saving model to weights.hd5\n",
            "INFO:tensorflow:Assets written to: weights.hd5/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 30s 75ms/step - loss: 1.3284 - accuracy: 0.4584 - val_loss: 1.3246 - val_accuracy: 0.4582\n",
            "Epoch 25/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.3195 - accuracy: 0.4722\n",
            "Epoch 00025: val_loss improved from 1.32458 to 1.29426, saving model to weights.hd5\n",
            "INFO:tensorflow:Assets written to: weights.hd5/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 31s 76ms/step - loss: 1.3193 - accuracy: 0.4724 - val_loss: 1.2943 - val_accuracy: 0.5102\n",
            "Epoch 26/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.2964 - accuracy: 0.4917\n",
            "Epoch 00026: val_loss improved from 1.29426 to 1.24225, saving model to weights.hd5\n",
            "INFO:tensorflow:Assets written to: weights.hd5/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 30s 75ms/step - loss: 1.2960 - accuracy: 0.4919 - val_loss: 1.2423 - val_accuracy: 0.5155\n",
            "Epoch 27/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.2575 - accuracy: 0.5119\n",
            "Epoch 00027: val_loss did not improve from 1.24225\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 1.2577 - accuracy: 0.5118 - val_loss: 1.2599 - val_accuracy: 0.5164\n",
            "Epoch 28/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.2472 - accuracy: 0.5245\n",
            "Epoch 00028: val_loss did not improve from 1.24225\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 1.2471 - accuracy: 0.5245 - val_loss: 1.5438 - val_accuracy: 0.4159\n",
            "Epoch 29/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.2260 - accuracy: 0.5357\n",
            "Epoch 00029: val_loss did not improve from 1.24225\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 1.2256 - accuracy: 0.5358 - val_loss: 1.3916 - val_accuracy: 0.4588\n",
            "Epoch 30/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.1917 - accuracy: 0.5449\n",
            "Epoch 00030: val_loss improved from 1.24225 to 1.19365, saving model to weights.hd5\n",
            "INFO:tensorflow:Assets written to: weights.hd5/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 30s 75ms/step - loss: 1.1918 - accuracy: 0.5449 - val_loss: 1.1937 - val_accuracy: 0.5540\n",
            "Epoch 31/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.1829 - accuracy: 0.5538\n",
            "Epoch 00031: val_loss did not improve from 1.19365\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 1.1828 - accuracy: 0.5540 - val_loss: 1.2034 - val_accuracy: 0.5390\n",
            "Epoch 32/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.1609 - accuracy: 0.5628\n",
            "Epoch 00032: val_loss improved from 1.19365 to 1.17304, saving model to weights.hd5\n",
            "INFO:tensorflow:Assets written to: weights.hd5/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 30s 75ms/step - loss: 1.1612 - accuracy: 0.5627 - val_loss: 1.1730 - val_accuracy: 0.5554\n",
            "Epoch 33/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.1379 - accuracy: 0.5711\n",
            "Epoch 00033: val_loss did not improve from 1.17304\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 1.1378 - accuracy: 0.5711 - val_loss: 1.1856 - val_accuracy: 0.5515\n",
            "Epoch 34/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.1080 - accuracy: 0.5834\n",
            "Epoch 00034: val_loss improved from 1.17304 to 1.15270, saving model to weights.hd5\n",
            "INFO:tensorflow:Assets written to: weights.hd5/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 30s 75ms/step - loss: 1.1078 - accuracy: 0.5835 - val_loss: 1.1527 - val_accuracy: 0.5686\n",
            "Epoch 35/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.0950 - accuracy: 0.5937\n",
            "Epoch 00035: val_loss improved from 1.15270 to 1.14674, saving model to weights.hd5\n",
            "INFO:tensorflow:Assets written to: weights.hd5/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 31s 77ms/step - loss: 1.0947 - accuracy: 0.5938 - val_loss: 1.1467 - val_accuracy: 0.5748\n",
            "Epoch 36/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.0738 - accuracy: 0.6009\n",
            "Epoch 00036: val_loss did not improve from 1.14674\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 26s 64ms/step - loss: 1.0738 - accuracy: 0.6010 - val_loss: 1.1719 - val_accuracy: 0.5652\n",
            "Epoch 37/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.0629 - accuracy: 0.6048\n",
            "Epoch 00037: val_loss did not improve from 1.14674\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 26s 64ms/step - loss: 1.0634 - accuracy: 0.6047 - val_loss: 1.1568 - val_accuracy: 0.5851\n",
            "Epoch 38/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.0415 - accuracy: 0.6141\n",
            "Epoch 00038: val_loss improved from 1.14674 to 1.14106, saving model to weights.hd5\n",
            "INFO:tensorflow:Assets written to: weights.hd5/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 30s 74ms/step - loss: 1.0412 - accuracy: 0.6143 - val_loss: 1.1411 - val_accuracy: 0.5910\n",
            "Epoch 39/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.0264 - accuracy: 0.6287\n",
            "Epoch 00039: val_loss did not improve from 1.14106\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 26s 63ms/step - loss: 1.0270 - accuracy: 0.6285 - val_loss: 1.1491 - val_accuracy: 0.5859\n",
            "Epoch 40/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 1.0008 - accuracy: 0.6362\n",
            "Epoch 00040: val_loss improved from 1.14106 to 1.13051, saving model to weights.hd5\n",
            "INFO:tensorflow:Assets written to: weights.hd5/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 30s 75ms/step - loss: 1.0011 - accuracy: 0.6361 - val_loss: 1.1305 - val_accuracy: 0.6017\n",
            "Epoch 41/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.9949 - accuracy: 0.6386\n",
            "Epoch 00041: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.9950 - accuracy: 0.6386 - val_loss: 1.1500 - val_accuracy: 0.5943\n",
            "Epoch 42/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.9745 - accuracy: 0.6499\n",
            "Epoch 00042: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 26s 63ms/step - loss: 0.9747 - accuracy: 0.6498 - val_loss: 1.1626 - val_accuracy: 0.5831\n",
            "Epoch 43/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.9492 - accuracy: 0.6581\n",
            "Epoch 00043: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 62ms/step - loss: 0.9494 - accuracy: 0.6581 - val_loss: 1.1790 - val_accuracy: 0.5873\n",
            "Epoch 44/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.9220 - accuracy: 0.6684\n",
            "Epoch 00044: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.9217 - accuracy: 0.6683 - val_loss: 1.1691 - val_accuracy: 0.5980\n",
            "Epoch 45/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.9019 - accuracy: 0.6778\n",
            "Epoch 00045: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.9014 - accuracy: 0.6780 - val_loss: 1.1966 - val_accuracy: 0.5941\n",
            "Epoch 46/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.8899 - accuracy: 0.6854\n",
            "Epoch 00046: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.8898 - accuracy: 0.6853 - val_loss: 1.2148 - val_accuracy: 0.5896\n",
            "Epoch 47/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.8667 - accuracy: 0.6902\n",
            "Epoch 00047: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.8664 - accuracy: 0.6902 - val_loss: 1.1847 - val_accuracy: 0.6144\n",
            "Epoch 48/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.8479 - accuracy: 0.6987\n",
            "Epoch 00048: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.8476 - accuracy: 0.6989 - val_loss: 1.1453 - val_accuracy: 0.6169\n",
            "Epoch 49/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.8182 - accuracy: 0.7127\n",
            "Epoch 00049: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.8187 - accuracy: 0.7127 - val_loss: 1.1910 - val_accuracy: 0.6147\n",
            "Epoch 50/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.8007 - accuracy: 0.7201\n",
            "Epoch 00050: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 62ms/step - loss: 0.8011 - accuracy: 0.7200 - val_loss: 1.2307 - val_accuracy: 0.6156\n",
            "Epoch 51/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.7709 - accuracy: 0.7311\n",
            "Epoch 00051: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.7712 - accuracy: 0.7309 - val_loss: 1.3303 - val_accuracy: 0.6187\n",
            "Epoch 52/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.7626 - accuracy: 0.7371\n",
            "Epoch 00052: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.7628 - accuracy: 0.7369 - val_loss: 1.2698 - val_accuracy: 0.6127\n",
            "Epoch 53/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.7294 - accuracy: 0.7474\n",
            "Epoch 00053: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.7293 - accuracy: 0.7474 - val_loss: 1.3313 - val_accuracy: 0.5884\n",
            "Epoch 54/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.7158 - accuracy: 0.7524\n",
            "Epoch 00054: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.7157 - accuracy: 0.7525 - val_loss: 1.3274 - val_accuracy: 0.6262\n",
            "Epoch 55/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.7061 - accuracy: 0.7604\n",
            "Epoch 00055: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.7060 - accuracy: 0.7604 - val_loss: 1.2759 - val_accuracy: 0.6135\n",
            "Epoch 56/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.6809 - accuracy: 0.7644\n",
            "Epoch 00056: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.6810 - accuracy: 0.7645 - val_loss: 1.3901 - val_accuracy: 0.6146\n",
            "Epoch 57/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.6638 - accuracy: 0.7724\n",
            "Epoch 00057: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.6639 - accuracy: 0.7724 - val_loss: 1.3710 - val_accuracy: 0.6269\n",
            "Epoch 58/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.6368 - accuracy: 0.7792\n",
            "Epoch 00058: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.6370 - accuracy: 0.7792 - val_loss: 1.4648 - val_accuracy: 0.6161\n",
            "Epoch 59/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.6213 - accuracy: 0.7887\n",
            "Epoch 00059: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.6212 - accuracy: 0.7888 - val_loss: 1.4797 - val_accuracy: 0.6245\n",
            "Epoch 60/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.6110 - accuracy: 0.7920\n",
            "Epoch 00060: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 26s 63ms/step - loss: 0.6110 - accuracy: 0.7919 - val_loss: 1.4608 - val_accuracy: 0.6229\n",
            "Epoch 61/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.5998 - accuracy: 0.7956\n",
            "Epoch 00061: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.5999 - accuracy: 0.7956 - val_loss: 1.4500 - val_accuracy: 0.6325\n",
            "Epoch 62/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.5693 - accuracy: 0.8063\n",
            "Epoch 00062: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.5694 - accuracy: 0.8064 - val_loss: 1.4678 - val_accuracy: 0.6327\n",
            "Epoch 63/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.5678 - accuracy: 0.8094\n",
            "Epoch 00063: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.5672 - accuracy: 0.8097 - val_loss: 1.5994 - val_accuracy: 0.6302\n",
            "Epoch 64/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.5488 - accuracy: 0.8173\n",
            "Epoch 00064: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.5488 - accuracy: 0.8172 - val_loss: 1.5507 - val_accuracy: 0.6350\n",
            "Epoch 65/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.5275 - accuracy: 0.8239\n",
            "Epoch 00065: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.5274 - accuracy: 0.8239 - val_loss: 1.6183 - val_accuracy: 0.6376\n",
            "Epoch 66/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.5143 - accuracy: 0.8270\n",
            "Epoch 00066: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.5137 - accuracy: 0.8272 - val_loss: 1.6583 - val_accuracy: 0.6228\n",
            "Epoch 67/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.5147 - accuracy: 0.8295\n",
            "Epoch 00067: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.5146 - accuracy: 0.8295 - val_loss: 1.6011 - val_accuracy: 0.6293\n",
            "Epoch 68/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.4945 - accuracy: 0.8353\n",
            "Epoch 00068: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.4945 - accuracy: 0.8354 - val_loss: 1.5386 - val_accuracy: 0.6325\n",
            "Epoch 69/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.4738 - accuracy: 0.8431\n",
            "Epoch 00069: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.4740 - accuracy: 0.8429 - val_loss: 1.6782 - val_accuracy: 0.6354\n",
            "Epoch 70/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.4723 - accuracy: 0.8424\n",
            "Epoch 00070: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 26s 63ms/step - loss: 0.4722 - accuracy: 0.8425 - val_loss: 1.6128 - val_accuracy: 0.6313\n",
            "Epoch 71/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.4667 - accuracy: 0.8456\n",
            "Epoch 00071: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 26s 64ms/step - loss: 0.4662 - accuracy: 0.8457 - val_loss: 1.6020 - val_accuracy: 0.6409\n",
            "Epoch 72/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.4468 - accuracy: 0.8539\n",
            "Epoch 00072: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 26s 63ms/step - loss: 0.4465 - accuracy: 0.8539 - val_loss: 1.6889 - val_accuracy: 0.6398\n",
            "Epoch 73/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.4477 - accuracy: 0.8542\n",
            "Epoch 00073: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 26s 63ms/step - loss: 0.4474 - accuracy: 0.8542 - val_loss: 1.8607 - val_accuracy: 0.6334\n",
            "Epoch 74/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.4181 - accuracy: 0.8621\n",
            "Epoch 00074: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.4183 - accuracy: 0.8620 - val_loss: 1.8798 - val_accuracy: 0.6354\n",
            "Epoch 75/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.4124 - accuracy: 0.8628\n",
            "Epoch 00075: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 26s 63ms/step - loss: 0.4128 - accuracy: 0.8626 - val_loss: 1.7783 - val_accuracy: 0.6271\n",
            "Epoch 76/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.4027 - accuracy: 0.8652\n",
            "Epoch 00076: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.4025 - accuracy: 0.8652 - val_loss: 1.7649 - val_accuracy: 0.6396\n",
            "Epoch 77/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.3903 - accuracy: 0.8746\n",
            "Epoch 00077: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.3905 - accuracy: 0.8744 - val_loss: 1.8584 - val_accuracy: 0.6364\n",
            "Epoch 78/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8744\n",
            "Epoch 00078: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.3850 - accuracy: 0.8744 - val_loss: 1.9576 - val_accuracy: 0.6337\n",
            "Epoch 79/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.3761 - accuracy: 0.8786\n",
            "Epoch 00079: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.3759 - accuracy: 0.8786 - val_loss: 1.9446 - val_accuracy: 0.6381\n",
            "Epoch 80/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.3642 - accuracy: 0.8800\n",
            "Epoch 00080: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.3644 - accuracy: 0.8799 - val_loss: 1.9761 - val_accuracy: 0.6378\n",
            "Epoch 81/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.3557 - accuracy: 0.8847\n",
            "Epoch 00081: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.3558 - accuracy: 0.8846 - val_loss: 1.9867 - val_accuracy: 0.6392\n",
            "Epoch 82/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.3506 - accuracy: 0.8842\n",
            "Epoch 00082: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.3507 - accuracy: 0.8841 - val_loss: 2.0792 - val_accuracy: 0.6378\n",
            "Epoch 83/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.3466 - accuracy: 0.8893\n",
            "Epoch 00083: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 26s 63ms/step - loss: 0.3469 - accuracy: 0.8891 - val_loss: 2.1257 - val_accuracy: 0.6362\n",
            "Epoch 84/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.3347 - accuracy: 0.8912\n",
            "Epoch 00084: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 26s 64ms/step - loss: 0.3345 - accuracy: 0.8912 - val_loss: 2.0418 - val_accuracy: 0.6207\n",
            "Epoch 85/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.3327 - accuracy: 0.8924\n",
            "Epoch 00085: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 26s 63ms/step - loss: 0.3329 - accuracy: 0.8923 - val_loss: 2.1170 - val_accuracy: 0.6421\n",
            "Epoch 86/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.3232 - accuracy: 0.8945\n",
            "Epoch 00086: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 26s 63ms/step - loss: 0.3232 - accuracy: 0.8944 - val_loss: 2.1829 - val_accuracy: 0.6364\n",
            "Epoch 87/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.3274 - accuracy: 0.8966\n",
            "Epoch 00087: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 26s 63ms/step - loss: 0.3274 - accuracy: 0.8966 - val_loss: 2.0499 - val_accuracy: 0.6402\n",
            "Epoch 88/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.3136 - accuracy: 0.8972\n",
            "Epoch 00088: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.3134 - accuracy: 0.8973 - val_loss: 2.1725 - val_accuracy: 0.6387\n",
            "Epoch 89/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.2993 - accuracy: 0.9016\n",
            "Epoch 00089: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.2997 - accuracy: 0.9015 - val_loss: 2.2460 - val_accuracy: 0.6444\n",
            "Epoch 90/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.3051 - accuracy: 0.9019\n",
            "Epoch 00090: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 26s 63ms/step - loss: 0.3048 - accuracy: 0.9020 - val_loss: 2.1493 - val_accuracy: 0.6443\n",
            "Epoch 91/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.2863 - accuracy: 0.9066\n",
            "Epoch 00091: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.2868 - accuracy: 0.9064 - val_loss: 2.2810 - val_accuracy: 0.6359\n",
            "Epoch 92/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.2844 - accuracy: 0.9087\n",
            "Epoch 00092: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.2845 - accuracy: 0.9087 - val_loss: 2.3313 - val_accuracy: 0.6409\n",
            "Epoch 93/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.2775 - accuracy: 0.9111\n",
            "Epoch 00093: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 26s 63ms/step - loss: 0.2774 - accuracy: 0.9111 - val_loss: 2.4070 - val_accuracy: 0.6464\n",
            "Epoch 94/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.2788 - accuracy: 0.9106\n",
            "Epoch 00094: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.2790 - accuracy: 0.9106 - val_loss: 2.3115 - val_accuracy: 0.6367\n",
            "Epoch 95/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.2777 - accuracy: 0.9122\n",
            "Epoch 00095: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.2776 - accuracy: 0.9122 - val_loss: 2.3123 - val_accuracy: 0.6420\n",
            "Epoch 96/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.2628 - accuracy: 0.9133\n",
            "Epoch 00096: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 26s 63ms/step - loss: 0.2628 - accuracy: 0.9133 - val_loss: 2.3349 - val_accuracy: 0.6350\n",
            "Epoch 97/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.2669 - accuracy: 0.9138\n",
            "Epoch 00097: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.2669 - accuracy: 0.9137 - val_loss: 2.4227 - val_accuracy: 0.6372\n",
            "Epoch 98/100\n",
            "404/404 [==============================] - ETA: 0s - loss: 0.2552 - accuracy: 0.9165\n",
            "Epoch 00098: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.2552 - accuracy: 0.9165 - val_loss: 2.4922 - val_accuracy: 0.6415\n",
            "Epoch 99/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.2493 - accuracy: 0.9195\n",
            "Epoch 00099: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.2491 - accuracy: 0.9196 - val_loss: 2.5034 - val_accuracy: 0.6382\n",
            "Epoch 100/100\n",
            "403/404 [============================>.] - ETA: 0s - loss: 0.2533 - accuracy: 0.9198\n",
            "Epoch 00100: val_loss did not improve from 1.13051\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "404/404 [==============================] - 25s 63ms/step - loss: 0.2532 - accuracy: 0.9198 - val_loss: 2.4702 - val_accuracy: 0.6373\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff324f8d6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_osnVPnG-kbL",
        "outputId": "a138070e-fa66-422c-a150-e199943243b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epochs = 100\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "\n",
        "model = Sequential()\n",
        "    \n",
        "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(48, 48, 1), kernel_regularizer=l2(0.01)))\n",
        "model.add(Conv2D(64, (3, 3), padding='same',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "    \n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "    \n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "    \n",
        "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(7, activation='softmax'))\n",
        "adam = optimizers.Adam(lr = learning_rate)\n",
        "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_11 (Conv2D)           (None, 46, 46, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 46, 46, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 46, 46, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 23, 23, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 23, 23, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 23, 23, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 23, 23, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 23, 23, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 23, 23, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 11, 11, 256)       295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 11, 11, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 11, 11, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 11, 11, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 11, 11, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 11, 11, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 5, 5, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 5, 5, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 5, 5, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 5, 5, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 5, 5, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 5, 5, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 7)                 455       \n",
            "=================================================================\n",
            "Total params: 9,014,727\n",
            "Trainable params: 9,009,223\n",
            "Non-trainable params: 5,504\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwike0JBA7__",
        "outputId": "6dbdb51e-c80a-4ed5-b0f7-98f15b5dc58a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install h5py\n",
        "!pip install pyyaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8wLkHfhBWCx",
        "outputId": "c9f10d27-51f1-48a1-dcc9-9886718f4ea9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Emotion_recognition.ipynb  fer2013.tar\t       test.csv\n",
            "example_submission.csv\t   fer2013.tar.gz      train.csv\n",
            "fer2013\t\t\t   icml_face_data.csv  weights.hd5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfpJp9P0ne7K",
        "outputId": "59d7b2f1-ec66-4ec6-b054-b85bced7970c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "predicted_test_labels = np.argmax(model.predict(test_data), axis=1)\n",
        "test_labels = np.argmax(test_labels, axis=1)\n",
        "print (\"Accuracy score = \", accuracy_score(test_labels, predicted_test_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score =  0.636110337141265\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqeihSv-9h5l",
        "outputId": "5cbd43a5-0a2e-462a-d21b-8d16b578d225",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.models import model_from_json\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH0slx2tmVxf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}